# K8s-数据管理

## Volume

我们经常会说：容器和 Pod 是短暂的。
其含义是它们的生命周期可能很短，会被频繁地销毁和创建。容器销毁时，保存在容器内部文件系统中的数据都会被清除。

为了持久化保存容器的数据，可以使用 Kubernetes Volume。

Volume 的生命周期独立于容器，Pod 中的容器可能被销毁和重建，但 Volume 会被保留。

本质上，Kubernetes Volume 是一个目录，这一点与 Docker Volume 类似。当 Volume 被 mount 到 Pod，Pod 中的所有容器都可以访问这个 Volume。Kubernetes Volume 也支持多种 backend 类型，包括 emptyDir、hostPath、GCE Persistent Disk、AWS Elastic Block Store、NFS、Ceph 等，完整列表可参考 https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes

Volume 提供了对各种 backend 的抽象，容器在使用 Volume 读写数据的时候不需要关心数据到底是存放在本地节点的文件系统中呢还是云硬盘上。对它来说，所有类型的 Volume 都只是一个目录。

## emptyDir

emptyDir 是最基础的 Volume 类型。一个 emptyDir Volume 是 Host 上的一个空目录。

emptyDir Volume 对于容器来说是持久的，对于 Pod 则不是。当 Pod 从节点删除时，Volume 的内容也会被删除。但如果只是容器被销毁而 Pod 还在，则 Volume 不受影响。

也就是说：emptyDir Volume 的生命周期与 Pod 一致。

Pod 中的所有容器都可以共享 Volume，它们可以指定各自的 mount 路径。

```
[root@k8s-master ~]# mkdir volumepod
[root@k8s-master ~]# cd !$

[root@k8s-master volumepod]# kubectl run producer-consumer --image=busybox --dry-run="client" -o yaml > producer-consumer.yaml

[root@k8s-master volumepod]# cat producer-consumer.yaml 
apiVersion: v1
kind: Pod
metadata:
  labels:
    run: producer-consumer
  name: producer-consumer
spec:
  containers:
  - image: busybox
    name: producer
    volumeMounts:
    - mountPath: /producer_dir
      name: shared-volume
    args: ["/bin/sh","-c","echo 'hello world' > /producer_dir/hello; sleep 999999"]

  - image: busybox
    name: consumer
    volumeMounts:
    - mountPath: /consumer_dir
      name: shared-volume
    args: ["/bin/sh","-c","cat /consumer_dir/hello; sleep 999999"]


  volumes:
  - name: shared-volume
    emptyDir: {}

[root@k8s-master volumepod]# kubectl apply -f producer-consumer.yaml

[root@k8s-master volumepod]# kubectl get pod -o wide 
NAME                READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES
producer-consumer   2/2     Running   0          62s   10.244.1.98   k8s-node1   <none>           <none>
[root@k8s-master volumepod]# kubectl logs producer-consumer consumer 
hello world

```

## hostpath

hostPath Volume 的作用是将 Docker Host 文件系统中已经存在的目录 mount 给 Pod 的容器。大部分应用都不会使用 hostPath Volume，因为这实际上增加了 Pod 与节点的耦合，限制了 Pod 的使用。不过那些需要访问 Kubernetes 或 Docker 内部数据（配置文件和二进制库）的应用则需要使用 hostPath。

比如 kube-apiserver 和 kube-controller-manager 就是这样的应用，通过 kubectl edit --namespace=kube-system pod kube-apiserver-k8s-master 查看 kube-apiserver Pod 的配置，下面是 Volume 的相关部分：

这里定义了三个 hostPath volume k8s、certs 和 pki，分别对应 Host 目录 /etc/kubernetes、/etc/ssl/certs 和 /etc/pki。

如果 Pod 被销毁了，hostPath 对应的目录也还会被保留，从这点看，hostPath 的持久性比 emptyDir 强。不过一旦 Host 崩溃，hostPath 也就没法访问了。

## PV & PVC 

PersistentVolume (PV) 是外部存储系统中的一块存储空间，由管理员创建和维护。与 Volume 一样，PV 具有持久性，生命周期独立于 Pod。

PersistentVolumeClaim (PVC) 是对 PV 的申请 (Claim)。PVC 通常由普通用户创建和维护。需要为 Pod 分配存储资源时，用户可以创建一个 PVC，指明存储资源的容量大小和访问模式（比如只读）等信息，Kubernetes 会查找并提供满足条件的 PV。

有了 PersistentVolumeClaim，用户只需要告诉 Kubernetes 需要什么样的存储资源，而不必关心真正的空间从哪里分配，如何访问等底层细节信息。这些 Storage Provider 的底层信息交给管理员来处理，只有管理员才应该关心创建 PersistentVolume 的细节信息。

## NFS PV

第一步：需在新节点上搭建了一个 NFS 服务器

```
# 所有节点安装
yum install -y rpcbind nfs-utils

# 配置nfs
[root@localhost ~]# mkdir /nfsdata
[root@localhost ~]# vim /etc/exports
[root@localhost ~]# systemctl restart rpcbind 
[root@localhost ~]# systemctl enable  rpcbind 
[root@localhost ~]# systemctl enable  nfs-server
Created symlink from /etc/systemd/system/multi-user.target.wants/nfs-server.service to /usr/lib/systemd/system/nfs-server.service.
[root@localhost ~]# systemctl restart  nfs-server
[root@localhost ~]# export
export    exportfs  
[root@localhost ~]# exportfs -ra
[root@localhost ~]# exportfs
/nfsdata      	<world>
[root@localhost ~]# cat /etc/exports
/nfsdata *(rw,async,no_root_squash)

# 其他节点测试
systemctl restart rpcbind
systemctl enable  rpcbind 
systemctl status rpcbind
showmount -e 192.168.10.14
	Export list for 192.168.10.14:
	/nfsdata *

```

```
# 创建pv
[root@k8s-master ~]# mkdir pvpvc
[root@k8s-master ~]# cd pvpvc/
[root@k8s-master pvpvc]# vim mypv1.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mypv1
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: nfs
  nfs:
    path: /nfsdata/pv1   #需要创建pv1目录，否则pod起不来
    server: 192.168.10.14
    
# 部署
[root@k8s-master pvpvc]# kubectl apply -f mypv1.yaml 
[root@k8s-master pvpvc]# kubectl get persistentvolume
NAME    CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
mypv1   1Gi        RWO            Recycle          Available           nfs                     7s

```

① capacity 指定 PV 的容量为 1G。

② accessModes 指定访问模式为 ReadWriteOnce，支持的访问模式有：

ReadWriteOnce – PV 能以 read-write 模式 mount 到单个节点。

ReadOnlyMany – PV 能以 read-only 模式 mount 到多个节点。

ReadWriteMany – PV 能以 read-write 模式 mount 到多个节点。

③ persistentVolumeReclaimPolicy 指定当 PV 的回收策略为 Recycle，支持的策略有：

Retain – 需要管理员手工回收。

Recycle – 清除 PV 中的数据，效果相当于执行 rm -rf /thevolume/*。

Delete – 删除 Storage Provider 上的对应存储资源，例如 AWS EBS、GCE PD、Azure Disk、OpenStack Cinder Volume 等。

④ storageClassName 指定 PV 的 class 为 nfs。相当于为 PV 设置了一个分类，PVC 可以指定 class 申请相应 class 的 PV。

⑤ 指定 PV 在 NFS 服务器上对应的目录。

```
# 创建 PVC
# PVC 就很简单了，只需要指定 PV 的容量，访问模式和 class。

[root@k8s-master pvpvc]# cat mypvc1.yaml 
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mypvc1
spec:
  accessModes: 
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: nfs

[root@k8s-master pvpvc]# kubectl get pv
NAME    CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM            STORAGECLASS   REASON   AGE
mypv1   1Gi        RWO            Recycle          Bound    default/mypvc1   nfs                     7m49s
[root@k8s-master pvpvc]# kubectl get pvc
NAME     STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
mypvc1   Bound    mypv1    1Gi        RWO            nfs            24s
```

```
# 接下来就可以在 Pod 中使用存储了

[root@k8s-master pvpvc]# kubectl apply -f mypod1.yaml 
pod/mypod1 created
[root@k8s-master pvpvc]# cat mypod1.yaml 
apiVersion: v1
kind: Pod
metadata:
  labels:
    run: mypod1
  name: mypod1
spec:
  containers:
  - image: busybox
    name: mypod1
    args: ["/bin/sh","-c","sleep 999999"]

    volumeMounts:
    - mountPath: "/mydata"
      name: mydata

  volumes:
  - name: mydata
    persistentVolumeClaim:
      claimName: mypvc1

[root@k8s-master pvpvc]# kubectl describe pod mypod1

# 加入容器写数据
[root@k8s-master pvpvc]# kubectl exec -it mypod1 sh
/ # cd /mydata/
/mydata # echo hi > hello

# 去nfs服务器查看文件

# 删除pod，文件在nfs依然存在
[root@k8s-master pvpvc]# kubectl delete -f mypod1.yaml

# 删除pvc，此时会删除pvc中的文件
[root@k8s-master pvpvc]# kubectl delete pvc mypvc1
[root@k8s-master pvpvc]# kubectl get pv mypv1 
NAME    CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
mypv1   1Gi        RWO            Recycle          Available           nfs                     37m


```

```
# 保留pv数据 [Retain]
# persistentVolumeReclaimPolicy: Retain

[root@k8s-master pvpvc]# vim mypv1.yaml 
[root@k8s-master pvpvc]# kubectl apply -f mypv1.yaml 
persistentvolume/mypv1 configured
[root@k8s-master pvpvc]# kubectl get pv mypv1 
NAME    CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
mypv1   1Gi        RWO            Retain           Available           nfs                     39m

# 申请pvc
[root@k8s-master pvpvc]# kubectl apply -f mypvc1.yaml 
persistentvolumeclaim/mypvc1 created
[root@k8s-master pvpvc]# kubectl get pv
[root@k8s-master pvpvc]# kubectl apply -f mypod1.yaml 
# 写入数据
[root@k8s-master pvpvc]# kubectl exec -it mypod1 -- sh
/ # cd /mydata/
/mydata # echo "test123" > hello 
/mydata # cat hello 
test123
# 删除pod和pvc或pv，文件依然存在
[root@k8s-master pvpvc]# kubectl delete -f mypod1.yaml 
[root@k8s-master pvpvc]# kubectl delete pvc mypvc1 
[root@k8s-master pvpvc]# kubectl get pv
NAME    CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM            STORAGECLASS   REASON   AGE
mypv1   1Gi        RWO            Retain           Released   default/mypvc1   nfs                     44m

```

## Mysql使用pv/pvc

1. 创建pv和pvc
2. 部署Mysql
3. 向Mysql添加数据
4. 模拟节点宕机，k8s自动迁移
5. 验证数据一致性



```
# 准备pv和pvc
mkdir /mysqlpod; cd /mysqlpod

[root@k8s-master mysqlpod]# cat mysql-pv.yml 
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mysql-pv
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: nfs
  nfs:
    path: /nfsdata/mysql-pv   #需要创建pv1目录，否则pod起不来
    server: 192.168.10.14
    
cat mysql-pvc.yml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pvc
spec:
  accessModes: 
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: nfs

# 部署pv/pvc
kubectl apply -f mysql-pv.yml 
kubectl apply -f mysql-pvc.yml 
kubectl get pv
kubectl get pvc
```

```
# 创建mysql副本

[root@k8s-master mysqlpod]# kubectl create deployment mysqldep --image=mysql:5.7 --dry-run=client -o yaml > mysqldep.yaml
[root@k8s-master mysqlpod]# kubectl create service nodeport mysqlsvc --tcp=3306:3306 --dry-run=client -o yaml >> mysqldep.yaml

[root@k8s-master mysqlpod]# cat mysqldep.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: mysqldep
  name: mysqldep
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysqldep
  template:
    metadata:
      labels:
        app: mysqldep
    spec:
      containers:
      - image: mysql:5.7
        name: mysql
        env:
        - name: MYSQL_ROOT_PASSWORD
          value: password
        ports:
        - containerPort: 3306
          name: mysql
        volumeMounts:
        - name: mysql-persostent-storage
          mountPath: "/var/lib/mysql"
      volumes:
      - name: mysql-persostent-storage
        persistentVolumeClaim:
          claimName: mysql-pvc
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: mysqlsvc
  name: mysqlsvc
spec:
  ports:
  - name: 3306-3306
    port: 3306
    protocol: TCP
    targetPort: 3306
  selector:
    app: mysql
  type: NodePort

# 部署mysql和svc
kubectl apply -f mysqldep.yaml 
kubectl get pod -o wide 
```

```
# 进入mysql，创建数据
# 或通过client连接


[root@k8s-master mysqlpod]# kubectl exec -it mysqldep-686d76fd65-k48dq -- sh
# mysql -uroot -ppassword
mysql> create database test;
mysql> use test
mysql> create table test1 (id int, name varchar(20));
mysql> insert into test1 values (1,'zs'),(2,'ls');
mysql> select * from test1;
+------+------+
| id   | name |
+------+------+
|    1 | zs   |
|    2 | ls   |
+------+------+
```

```
# 模拟节点宕机
# 关闭mysql容器运行的节点[比如k8s-node2]
# 一段时间后，mysql将迁移到 k8s-node1
# Mysql服务恢复后，验证数据的一致性
```

