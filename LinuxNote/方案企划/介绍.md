

### **个人技能**

在上家公司主要负责linux服务器的日常维护和故障排查，负责对常用服务的部署，优化还有监控

目前比较熟悉nginx，apache和tomcat 这些常见的web服务，能够编写shell和python脚本辅助进行工作，熟悉lvs，nginx的负载均衡和keepalived的高可用架构，还有mysql数据库的主从和高可用集群的搭建部署，熟悉zabbix监控和ansible自动化运维工具的使用，对kvm虚拟化技术，docker和k8s容器技术也有一定的了解

### **ansible更新10台tomcat**

ansible常用模块：command，shell，copy，service，yum，user，group

ansible-playbook 使用 `serial `实现服务滚动更新实例

- 三步：停止，更新，启动；
- 保证服务运行；

```
默认情况下，Ansible 将尝试并行管理 playbook 中所有的机器。对于滚动更新用例，可以使用 serial 关键字定义 Ansible 一次应管理多少主机
将 serial 关键字指定为百分比，表示每次并行执行的主机数占总数的比例
将 serial 关键字指定为数字，如 2，表示每次并行执行的主机数为 2，多批次直到执行完成

---
- hosts: all
  serial: 33%
  remote_user: root
  gather_facts: no

  tasks:
    - name: "1. stop tomcat"
      shell: echo "/usr/local/tomcat8/bin/catalina.sh stop"
    - name: "2. copy webapp"
      shell: echo "copy webapp..."
    - name: "3. start tomcat"
      shell: echo "/usr/local/tomcat8/bin/catalina.sh start"
```

### **elk收集nginx日志**

- 两组业务，两组日志

- 在filebeat对不同业务日志 创建自定义索引 fields[字段]

```
[vim /etc/filebeat/filebeat.yml]

# 定义app、zabbix、nginx等应用的input类型、以及存放的具体路径
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/*.log
  fields: 
    source: app
- type: log
  enabled: true
  paths:
    - /var/log/nginx/*.log
  fields:
    source: nginx
    
filebeat.config.modules:
  path: ${path.config}/modules.d/*.yml
  reload.enabled: true
  
setup.template.settings:
  index.number_of_shards: 1
  
# 定义kibana的IP:PORT
setup.kibana:
  host: "192.168.10.11:5601"

# 定义模板的相关信息  
setup.template.name: "lile_log"
setup.template.pattern: "lile-*"
setup.template.overwrite: true
setup.template.enabled: true
# 在7.4这个版本中，自定义ES的索引需要把ilm设置为false
setup.ilm.enabled: false

# 定义app、zabbix、nginx的output
output.elasticsearch:
  # 定义ES的IP:PORT
  hosts: ["192.168.10.11:9200"]
  # 这里的index前缀lile与模板的pattern匹配，中间这一串设置为field.source变量，方面后面具体的匹配
  index: "lile-%{[fields.source]}-*"
  indices:
    # 这里的前缀lile同为与模板的pattern匹配，中间为field.source具体的值，当前面的input的field.source值与这里的匹配时，则index设置为定义的
    - index: "lile-app-%{+yyyy.MM.dd}"
      when.equals:
        fields:
            source: "app"

    - index: "lile-nginx-%{+yyyy.MM.dd}"
      when.equals: 
        fields.source: "nginx"
  
processors:
  - add_host_metadata: ~
  - add_cloud_metadata: ~
```

- kibana配置索引

![img](https://gitee.com/luoxian1011/pictures/raw/master/2018101212062652)



---

### 网络命令

tcpdump：网络抓包工具

ss / netstat：查看网络端口

ip addr / ifconfig：查看ip地址

路由 与 添加路由

```
// 添加到主机的路由
# route add -host 192.168.1.2 dev eth0 
# route add -host 10.20.30.148 gw 10.20.30.40     #添加到10.20.30.148的网管
// 添加到网络的路由
# route add -net 10.20.30.40 netmask 255.255.255.248 eth0   #添加10.20.30.40的网络  
# route add -net 10.20.30.48 netmask 255.255.255.248 gw 10.20.30.41 #添加10.20.30.48的网络  
// 添加默认路由
# route add default gw 192.168.1.1
```

---

### shell脚本

`shell 脚本接收参数`

- 采用\$0,​\$1,$2..等方式获取脚本命令行传入的参数
- $#	传递到脚本的参数个数
- \$*	以一个单字符串显示所有向脚本传递的参数。输出：\$1 \$2 … $n"

`shell 脚本`

- 日志切割轮替，mysql备份，磁盘占用的报警，服务部署脚本，mysql主从监控，redis集群监控，检查服务进程是否存活

` shell 三剑客`

- awk 
  - df -Th | awk '{print $3}'  // 输出第三列
  - awk '{print $NF}'  // 输出最后一列
- sed -i  // 直接修改文件
- grep 
  - -i 忽略大小写
  - -A 显示匹配行 和 后面的行数，在错误日志查找时还是很有用
  - -a 搜索二进制文件,表示把所有文件当作ASCII文件来处理
  - -e 高级

`python脚本`：常用库sys，os，time，random，shutil

### top进程负载

`top`

- 1、5和15分钟内的平均负载  平均活跃进程数  ，可以用-n N 指定输出次数
- load 20 cpu计算的队列 cpu个数来确定load的临界值；系统识别为8个cpu，那么load为8就是临界点，高于8就属于over load了
- 僵尸进程：
  - 一个子进程结束，但是父进程没有等待(调用wait / waitpid)他， 子进程的 PID 和 进程描述符 等资源仍然保存在系统中，就变成一个僵尸进程
  - ps -ef | grep defunct_process_pid（僵尸进程pid） 然后执行，kill -s 9 父进程的pid

`lsof`

- lsof：查看占用文件的进程

- lsof（list open files）是一个列出当前系统打开文件的工具

`crontab`：计划任务

---

### linux系统的操作

系统安全加固，扫描漏洞，对有漏洞的主栈进行升级

1. 设置复杂密码：服务器设置大写、小写、特殊字符、数字组成的12-16位的复杂密码
2. 设置密码策略：修改文件/etc/login.defs 密码最长有效期；密码修改之间最小的天数
3. 对用户的登录次数进行限制 编辑文件 /etc/pam.d/sshd；am_tally2 查看被锁定的用户
4. 禁止root用户远程登录：修改/etc/ssh/sshd_config
5. 更改ssh端口
6. 设置账户保存历史命令条数，超时时间  /etc/profile 五分钟未动，服务器超时自动断开与客户端的链接
7. 定期备份数据



硬件故障维护，硬盘故障

磁盘扩容：分区扩容工具(fdisk/e2fsck/resize2fs)

---

### web服务

#### nginx优化

主要做静态页面，反向代理，rewrite使用[新旧域名的跳转]，301永久重定向；apache和nginx的区别[tomcat]

1. 优化工作进程数
2. 开启CPU亲和力
3. 修改最多可以打开文件数，与ulimit -n的值保持一致
4. 使用epoll事件处理模型
5. 开启高效传输
6. 配置连接超时时间
7. fastcgi 调优
8. gzip 调优
9. expires 缓存调优
10. 防盗链
11. 内核参数优化

---

#### tomcat优化

- jvm优化
- 线程池并发优化
- APR模式配置
- 缓存压缩优化
- 安全优化
- 监控：线程，堆内存，内存池

![img](https://gitee.com/luoxian1011/pictures/raw/master/17001015223849.png)

- 使用jmx来获取到tomcat这类应用的状态，然后再将数据交给server端，生成监控图

```
1、Tomcat开启JMX远程连接
2、安装Zabbix Java Gateway
3、创建JMX主机
```

- JC垃圾回收

### zabbix服务端优化

- 配置文件优化：日志大小，轮询进程数，缓存，超时配置

```
#通过日志可以分析当前服务状态。
LogFile=/tmp/zabbix_server.log	#日志文件路径。
LogFileSize=1	#日志文件最大值(MB),超过则滚动,设为0表示不回滚。
DebugLevel=3	#调试日志级别：
#	0 - Zabbix进程启停基本信息。
#	1 - 严重信息。
#	2 - 错误信息。
#	3 - 警告。
#	4 - 调试模式。
#	5 - 调试模式-加强版。

#数据库配置，若数据库与服务器在同一机器上，使用socket模式可以提高访问速度。
DBSocket=/tmp/mysql.sock

#轮询进程数，通过并发来提高轮询或者捕获的效率，同时用来避免poller busy问题，根据CPU数量与系统负载综合调优。
StartPollers=80	#基本轮询进程数，范围0-1000。
StartIPMIPollers=0	#IPMI轮询进程数，若无智能卡监控，可置为0。
StartPollersUnreachable=1	#不可达主机的轮询进程数，包括IPMI和JAVA。
StartTrappers=1	#捕获模式进程数，若无active模式的客户端，则可减小该进程。
StartPingers=20	#ICMP ping数量，当大量使用ping用于心跳检测时，可适量增加。
StartDiscoverers=1	#自动发现实例数，若关闭此功能则减少该数量。
StartHTTPPollers=7	#HTTP轮询实例数，当使用到内置的WEB监测时，适量增加该值。
StartTimers=1	#定时器实例数。
StartEscalators=20	#扩展实例数。
StartDBSyncers=20 #DB同步器线程数。
StartJavaPollers=5 #JAVA轮询实例，当大量监控JMX时需要增加此项。
StartProxyPollers=1	#代理轮询线程。

#缓存配置
CacheSize=8M	#128K-8G，缓存配置项的大小，用于存储 host， item， trigger 数据。监控项
CacheUpdateFrequency=60	#提交缓存频率。
HistoryCacheSize=16M	#历史缓存大小。
HistoryIndexCacheSize=4M	#历史索引缓存大小。
TrendCacheSize=4M	#趋势缓存大小。
ValueCacheSize=8M	#历史项目值缓存，设为0表示禁用项目值缓存，history value 缓存大小，当缓存超标了，将会每隔 5 分钟往 server 日志里面记录。

#用户配置
AllowRoot=0	#是否允许使用 root 启动， 0:不允许， 1:允许，默认情况下她会使用 zabbix 用户来启动 zabbix 进程。
User=zabbix	#服务使用的用户。

#超时配置
Timeout=4	#端探测超时时间。
TrapperTimeout=300	#捕捉器超时时间。
UnreachablePeriod=45	#不可达时间，超过视为不可达。
UnavailableDelay=60	#不可达期间尝试周期。
UnreachableDelay=15	#不可用期间尝试周期。
HousekeepingFrequency=1	#housekeeping 数据归档周期(h)，housekeep 执行频率，默认每小时回去删除一些过期数据。如果 server 重启，那么 30 分钟之后才执行一次，接下来，每隔一小时在执行一次。。
MaxHousekeeperDelete=5000	#housekeeper表记录,一次删除的数据不能大于 MaxHousekeeperDelete。
SenderFrequency=30	#Zabbix尝试发送未发送数据频率，5-3600s。
```

- 对zabbix数据库结构进行优化

例如：对history.\*、trends.* 表进行分表操作，会很大的提高数据库的性能。

直接使用分区脚本操作，配置数据库连接信息，关闭zabbix-server，然后执行

```
wget https://dl.cactifans.com/zabbix/partitiontables_gt_zbx34.sh
```

history和trends相关表数据量很大，一个是历史数据，一个是趋势数据，脚本中默认详情数据保留30天，趋势数据保留12个月

- 使用主动模式获取监控数据



### mysql

mysql的了解[主从和高可用]



主从同步原理：

- 主库发送更新事件到从库
- 从库读取更新记录，并执行更新记录



数据库备份策略

- 主从热备；
- 全备+增量备份；

### docker

docker 常用命令

- images
- run
- ps
- exec
- start / stop
- logs
- save / load
- push / pull
- build
- docker-compose up -d / ps / down

### k8s架构

Kubernetes属于主从分布式架构，主要由Master Node和Worker Node组成，以及包括客户端命令行工具kubectl和其它附加项。

- Master Node：
  - Master 是 Kubernetes Cluster 的控制节点，运行着如下 Daemon 服务：kube-apiserver、kube-scheduler、kube-controller-manager、etcd 和 Pod 网络（例如 flannel）。
- Node 节点
  - Node 是 Pod 运行的地方，pod是k8s的最小工作单元。每个pod可以包含一个或者多个容器。pod中的容器会作为一个整体被master调度到一个node上运行。
  - Kubernetes 支持 Docker、rkt 等容器 Runtime。 Node上运行的 Kubernetes 组件有 kubelet、kube-proxy 和 Pod 网络（例如 flannel）



