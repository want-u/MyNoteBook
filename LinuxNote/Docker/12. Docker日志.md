# Docker日志

Docker  日志分为两类：

- Docker 引擎日志(也就是 dockerd 运行时的日志)
- 容器的日志，容器内的服务产生的日志

## 1. Docker引擎日志

Docker 引擎日志一般是交给了 Upstart(Ubuntu 14.04) 或者 systemd (CentOS 7, Ubuntu 16.04)。

- Ubuntu：一般位于 /var/log/upstart/docker.log 下
- CentOS：我们一般 通过  journalctl -u docker 来进行查看。

## 2. Docker容器日志

### 2.1 docker logs

`docker logs CONTAINER` 显示当前运行的容器的日志信息

```
Usage:  docker logs [OPTIONS] CONTAINER
Fetch the logs of a container
Options:
      --details        Show extra details provided to logs
  -f, --follow         Follow log output
      --since string   Show logs since timestamp (e.g. 2013-01-02T13:23:37Z) or relative
                       (e.g. 42m for 42 minutes)
  -n, --tail string    Number of lines to show from the end of the logs (default "all")
  -t, --timestamps     Show timestamps
      --until string   Show logs before a timestamp (e.g. 2013-01-02T13:23:37Z) or
                       relative (e.g. 42m for 42 minutes)
```

UNIX 和 Linux 的命令有三种 输入输出，分别是 STDIN(标准输入)、STDOUT(标准输出)、STDERR(标准错误输出)

docker logs  显示的内容包含 STOUT 和 STDERR。

在生产环境，如果我们的应用输出到我们的日志文件里，所以我们在使用  docker  logs 一般收集不到太多重要的日志信息。

```
nginx 官方镜像，使用了一种方式，让日志输出到 STDOUT，也就是 创建一个符号链接/var/log/nginx/access.log 到 /dev/stdout。

httpd 使用的是 让其输出到指定文件 ，正常日志输出到 /proc/self/fd/1 (STDOUT) ，错误日志输出到 /proc/self/fd/2 (STDERR)。

当日志量比较大的时候，我们使用 docker logs   来查看日志，会对 docker daemon 造成比较大的压力，容器导致容器创建慢等一系列问题。

只有使用了 `local 、json-file、journald`  的日志驱动的容器才可以使用 docker logs 捕获日志，使用其他日志驱动无法使用 `docker logs`
```

### 2.2 Docker日志驱动

Docker 提供了两种模式用于将消息从容器到日志驱动。

- (默认)拒绝，阻塞从容器到容器驱动
- 非阻塞传递,日志将储存在容器的缓冲区。

```
当缓冲区满，旧的日志将被丢弃。

在 mode 日志选项控制使用 blocking(默认) 或者 non-blocking, 当设置为 non-blocking需要设置 max-buffer-size 参数(默认为 1MB)。
```

#### 2.2.1 支持的驱动

|              | 描述                                                         |
| :----------- | :----------------------------------------------------------- |
| `none`       | 运行的容器没有日志，`docker logs`也不返回任何输出。          |
| `local`      | 日志以自定义格式存储，旨在实现最小开销。                     |
| `json-file`  | 日志格式为JSON。Docker的默认日志记录驱动程序。               |
| `syslog`     | 将日志消息写入`syslog`。该`syslog`守护程序必须在主机上运行。 |
| `journald`   | 将日志消息写入`journald`。该`journald`守护程序必须在主机上运行。 |
| `gelf`       | 将日志消息写入Graylog扩展日志格式（GELF）端点，例如Graylog或Logstash。 |
| `fluentd`    | 将日志消息写入`fluentd`（转发输入）。该`fluentd`守护程序必须在主机上运行。 |
| `awslogs`    | 将日志消息写入Amazon CloudWatch Logs。                       |
| `splunk`     | 使用HTTP事件收集器将日志消息写入`splunk`。                   |
| `etwlogs`    | 将日志消息写为Windows事件跟踪（ETW）事件。仅适用于Windows平台。 |
| `gcplogs`    | 将日志消息写入Google Cloud Platform（GCP）Logging。          |
| `logentries` | 将日志消息写入Rapid7 Logentries。                            |

#### 2.2.2 常用命令

查看系统当前设置的日志驱动

```
docker  info |grep  "Logging Driver"
docker info --format '{{.LoggingDriver}}'
```

查看单个容器的设置的日志驱动

```
docker inspect  -f '{{.HostConfig.LogConfig.Type}}'   容器id
```

Docker 日志驱动全局配置更改

修改日志驱动，在配置文件 `/etc/docker/daemon.json`（注意该文件内容是 JSON 格式的）进行配置即可。

```
{
  "log-driver": "syslog"
}
```

Docker 单一容器日志驱动配置

```
# 在 运行容器的时候指定 日志驱动 --log-driver
# 这里指定的日志驱动为 none 
[root@server1 ~]# docker run -dit --log-driver none busybox sh

[root@server1 ~]# docker logs 77cebe3825b2
Error response from daemon: configured logging driver does not support reading
```

#### 2.2.3 默认驱动

所有容器默认的日志驱动 `json-file`

json-file  日志的路径位于 `/var/lib/docker/containers/container_id/container_id-json.log`。

`json-file` 的日志驱动示例：

```
# 设置 日志驱动为 json-file ，我们也可以不设置，因为默认就是 json-file
docker run  -itd  --name  test-log-json  --log-driver json-file   alpine  ping www.baidu.com
199608b2e2c52136d2a17e539e9ef7fbacf97f1293678aded421dadbdb006a5e
 
# 查看日志,日志名称就是 容器名称-json.log
tail -f /var/lib/docker/containers/199608b2e2c52136d2a17e539e9ef7fbacf97f1293678aded421dadbdb006a5e/199608b2e2c52136d2a17e539e9ef7fbacf97f1293678aded421dadbdb006a5e-json.log
 
{"log":"64 bytes from 14.215.177.39: seq=13 ttl=55 time=15.023 ms\r\n","stream":"stdout","time":"2019-05-16T14:13:54.003118877Z"}
```

## 3. ELK容器

## ELK

ELK是三个软件的合称：Elasticsearch,Logstash,Kibana.

Logstash 负责从各个 Docker 容器中提取日志， Logstash将日志转发到Elasticsearch进行索引和保存，Kibana分析和可视化数据。

- Elasticsearch

  一个近乎实时查询的全文搜索引擎。
  Elasticsearch 的设计目标就是要能够处理和搜索巨量的日志数据。

- Logstash

  读取原始日志，并对其进行分析和过滤，然后将其转发给其他组件进行索引或存储。Logstash支持丰富的 Input 和 Output 类型，能够处理各种应用的日志。

- Kibana

  一个基于 JavaScript 的 Web 图形界面程序，专门用于可视化 Elasticsearch 的数据，Kibana 能够查询 Elasticsearch并通过丰富的图表展示结果，用户可以创建 Dashboard 来监控系统的日志。

### 3.1 运行ELK容器

**安装条件：**

​	Docker至少4GB内存；
​	Elasticsearch至少2GB内存；
​	防火墙开放端口；
​	vm.max_map_count至少需要262144

```
[root@server1 ~]# echo "vm.max_map_count = 262144" > /etc/sysctl.conf && sysctl -p
```

1. 下载镜像

```
# 这里我们使用elk集成镜像，地址：https://hub.docker.com/r/sebp/elk/tags

[root@server1 ~]# docker pull sebp/elk:793
```

2. 启动容器

```
[root@server1 ~]# docker run -p 5601:5601 -p 9200:9200 -p 5044:5044 -dit -e ES_HEAP_SIZE="2g" -e  LS_HEAP_SIZE="1g"  --name elk sebp/elk:793

# 说明：
# 启动堆栈，运行具有2GB堆大小的Elasticsearch和具有1GB堆大小的Logstash
# -p 指定映射端口
# 5601：（Kibana web 界面）
# 9200：（Elasticsearch JSON 接口）
# 5044：（Logstash Beats界面，从Beats接受日志，如Filebeat）

# 查看日志
[root@server1 ~]# docker logs -f elk
```

3. 访问

启动后等待数据初始化后，浏览器输入：192.168.10.11:5601，可看到kibana web界面

![image-20210130160403228](https://gitee.com/luoxian1011/pictures/raw/master/image-20210130160403228.png)

4. 文件目录

```
# 通过docker exec -it elk /bin/bash可进入容器中
# 具体各服务配置文件路径如下

[root@centos-mq ~]# docker exec -it elk /bin/bash
/etc/logstash/        ## logstash 配置文件路径
/etc/elasticsearch/   ##es 配置文件路径
/var/log/             ## 日志路径
```

### 3.2 安装FIlebeat

![image-20210130160454502](https://gitee.com/luoxian1011/pictures/raw/master/image-20210130160454502.png)

![image-20210130160515579](https://gitee.com/luoxian1011/pictures/raw/master/image-20210130160515579.png)

或直接访问页面：http://192.168.10.11:5601/app/home#/tutorial/elasticsearchLogs

切换到RPM：

![image-20210130160709656](https://gitee.com/luoxian1011/pictures/raw/master/image-20210130160709656.png)

filebeat部署，版本最好与elk一直，这里也选择793版本，filebeat部署在应用所在服务器，进行日志收集，日志样例；

1. 下载安装

```
curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.9.3-x86_64.rpm
sudo rpm -vi filebeat-7.9.3-x86_64.rpm
```

2. 编辑配置文件/etc/filebeat/filebeat.yml

```
[root@vanje-dev02 ~]# vim /etc/filebeat/filebeat.yml 
#=========================== Filebeat inputs 
filebeat.inputs:- type: log
  enabled: true  # 设置为true
  paths:
    - /var/lib/docker/containers/*/*.log # 容器日志的位置
    - /var/log/messages     ## 日志路径

# =================================== Kibana 
host: "192.168.10.11:5601"

# ---------------------------- Elasticsearch Output -
output.elasticsearch:
  # Array of hosts to connect to.
  hosts: ["192.168.10.11:9200"]
```

3. 启动elasticsearch模块

```
[root@localhost ~]# filebeat  modules enable elasticsearch
```

4. 初始化filebeat

```
[root@localhost ~]# filebeat setup
```

5. 启动

```
[root@localhost ~]# systemctl  start filebeat.service
[root@localhost ~]# systemctl  enable filebeat.service
```

6. 接下来，启动一个容器，模拟日志输出：

```
[root@localhost ~]# docker run busybox sh -c "while true;do echo 'this is a test';sleep 10;done;"
```

### 3.3 万能数据收集器 Fluentd

Fluentd是一个开源的数据收集器，他目前有超过500种的 plugin，可以连接各种数据源和数据输出组件。

1. 安装Fluentd

```
[root@localhost ~]# docker pull fluent/fluentd
[root@localhost ~]# docker run -d -p 24224:24224/tcp -p 24224:24224/udp -v /data:/fluentd/log fluent/fluentd
```

fluentd会在 TCP/UDP 端口 24224上接收日子数据，日志将保存在 Host的 /data目录中。

2. 编辑 Filebeat配置文件

```
filebeat.inputs:

# Each - is an input. Most options can be set at the input level, so
# you can use different inputs for various configurations.
# Below are the input specific configurations.

- type: log

  # Change to true to enable this input configuration.
  enabled: true

  # Paths that should be crawled and fetched. Glob based paths.
  paths:
    - /data/*.log
```

3. 重启服务

```
[root@localhost ~]# systemctl restart filebeat
```

4. 监控容器日志 启动测试

```
[root@localhost ~]# docker run -d  --log-driver=fluentd  --log-opt fluentd-address=localhost:24224  --log-opt tag="con-A"  busybox sh -c "while true;do echo 'this is A';sleep 10;done;"
332d96e156d13296a1a958bc6a3e3c700eb26b19c65756fcfd894cecc296e80e
[root@localhost ~]# docker run -d  --log-driver=fluentd  --log-opt fluentd-address=localhost:24224  --log-opt tag="con-B"  busybox sh -c "while true;do echo 'this is B';sleep 10;done;"
b540c1f0f7629270b368daec211927c9f24367476996baceaf0e19db2893b02c

# 1 - -log-friver=fluentd 告诉 Docker 使用 Fluentd 的logging driver。
# 2 - -log-opt fluentd-address=localhost:24224 将容器日志发送到 Fluentd 的数据接收端口。
# 3 - -log-opt tag=“con-A” 在日志中添加一个可选的 atg，用于区分不同的容器。
```

**查看日志**

![image-20210130161557970](https://gitee.com/luoxian1011/pictures/raw/master/image-20210130161557970.png)