# Docker Swarm

## 1. 概念

**docker-swarm是解决多主机多个容器调度部署得问题。**
Swarm是Docker 引擎内置（原生）的集群管理和编排工具。Docker Swarm是 Docker 官方三剑客项目之一，swarm是基于docker平台实现的集群技术，他可以通过几条简单的指令快速的创建一个docker集群，接着在集群的共享网络上部署应用，最终实现分布式的服务。

**Docker swarm中有三种角色：**

- **manager node:** 负责执行容器的编排和集群的管理工作，保持并维护swarm处于期望的状态。swarm可以有多个manager node，他们会自动协调并选举出一个Leader执行编排任务。但相反，不能没有managernode。
- **worker node:** 接受并执行由manager node 派发的任务，并且默认manager node也是一个work node，不过可以将它设置为manager-onlynode.让它只负责编排和管理工作。
- **service:** 用来定义worker上执行的命令。

**Swarm命令行说明**：

```
docker swarm：集群管理
init          #初始化集群
join          #将节点加入集群
join-token    #管理加入令牌
leave         #从集群中删除某个节点，强制删除加参数--force 
update        #更新集群
unlock        #解锁集群
```

```
docker node：节点管理，
demote      #将集群中一个或多个节点降级
inspect     #显示一个或多个节点的详细信息
ls          #列出集群中的节点
promote     #将一个或多个节点提升为管理节点
rm          #从集群中删除停止的节点，--force强制删除参数
ps          #列出一个或多个节点上运行的任务
update      #更新节点
```

```
docker service：服务管理，
create      #创建一个新的服务
inspect     #列出一个或多个服务的详细信息
ps          #列出一个或多个服务中的任务信息
ls          #列出服务
rm          #删除一个或多个服务
scale       #扩展一个或多个服务
update      #更新服务
```

## 2. 准备环境

### 2.1 实验拓扑

[基础为docker环境]

|     主机      |      IP       |  角色   |
| :-----------: | :-----------: | :-----: |
| swarm-manager | 192.168.10.11 | manager |
| swarm-worker1 | 192.168.10.12 | worker  |
| swarm-worker2 | 192.168.10.13 | worker  |

```
# 修改hosts文件
vim /etc/hosts

192.168.10.11 swarm-manager
192.168.10.12 swarm-worker1
192.168.10.13 swarm-worker2
```

```
# 关闭selinux
sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config

# 开启防火墙端口
# 2377/tcp（管理端口）
# 7946/udp（节点间通信端口）
# 4789/udp（overlay 网络端口）
firewall-cmd --add-port={2377,4789,7946}/tcp --permanent
firewall-cmd --add-port={4789,7946}/udp --permanent
firewall-cmd --reload
```

### 2.2 搭建私有仓库

在swarm-manager上操作

```
# 准备docker镜像
docker pull nginx
docker pull centos
docker pull busybox
docker pull registry # 私有仓库
```

```
# 启动registry
[root@swarm-manager ~]# docker run -dit --name registry -p 5000:5000 -v /var/registry:/var/lib/registry --restart always registry

# 查看查看镜像
[root@swarm-manager ~]# curl 192.168.10.11:5000/v2/_catalog
{"repositories":[]}

# 添加配置
vi /etc/docker/daemon.json
{
"registry-mirrors":[
        "https://8p2ftmks.mirror.aliyuncs.com"
    ],
"insecure-registries": [
        "192.168.10.11:5000"
    ]
}

# 重启docker
sudo systemctl   daemon-reload
systemctl restart docker.service
docker info
```

```
# 打上私有仓库的标签
[root@swarm-manager ~]# docker tag busybox:latest 192.168.10.11:5000/busybox
[root@swarm-manager ~]# docker tag nginx:latest 192.168.10.11:5000/nginx
[root@swarm-manager ~]# docker tag centos:latest 192.168.10.11:5000/centos

# 上传到私有仓库
[root@swarm-manager ~]# docker push 192.168.10.11:5000/busybox
[root@swarm-manager ~]# docker push 192.168.10.11:5000/nginx
[root@swarm-manager ~]# docker push 192.168.10.11:5000/centos

# 查看仓库镜像
[root@swarm-manager ~]# curl 192.168.10.11:5000/v2/_catalog
{"repositories":["busybox","centos","nginx"]}
```

### 2.3 ssh无密连接

```
# 三台之间，无密互联
# 生成密钥
[root@swarm-manager ~]# ssh-keygen -t rsa
# 拷贝到其他节点
[root@swarm-manager ~]# ssh-copy-id swarm-worker1
[root@swarm-manager ~]# ssh-copy-id swarm-worker2

# ssh swarm-worker1
# ssh-keygen -t rsa
# ssh-copy-id swarm-manager
# ssh-copy-id swarm-worker2

# ssh swarm-worker2
# ssh-keygen -t rsa
# ssh-copy-id swarm-manager
# ssh-copy-id swarm-worker1
# 退出，返回到swarm-manager
```

```
# 就docker的配置文件拷贝[私有仓库配置信息]
[root@swarm-manager ~]# scp /etc/docker/daemon.json swarm-worker1:/etc/docker/
[root@swarm-manager ~]# scp /etc/docker/daemon.json swarm-worker2:/etc/docker/
# 在其他节点重启docker
sudo systemctl   daemon-reload
systemctl restart docker.service
# 检查私有仓库地址是否正确
docker info
```

## 3. swarm集群

### 3.1 swarm初始化

```
# 初始化swarm集群
# --advertise-addr 指定与其他 node 通信的地址
# 会生成加入节点的命令：docker swarm join --token...
[root@swarm-manager ~]# docker swarm init --advertise-addr 192.168.10.11
```

docker swarm init 输出告诉我们： 

1. swarm 创建成功，swarm-manager 成为 manager node。 
2. 添加 worker node 需要执⾏的命令。 
3. 添加 manager node 需要执⾏的命令。 

```
# 查看集群的节点
[root@swarm-manager ~]# docker node  ls

# 复制前⾯的 docker swarm join 命令
# 在其他节点加入集群，在swarm-node2和swarm-node3上执行
docker swarm join --token SWMTKN-1-2sztfer3ifyrio1tmhlla6tsgbo0f2m0pks2sk4hs16cbwg9rd-1h1uvp5rabutkyu5ev4jix3t4 192.168.10.11:2377

# 显示 token值，此命令只能在 manager node 上执⾏
[root@swarm-manager ~]# docker swarm join-token worker
[root@swarm-manager ~]# docker swarm join-token manager

# 查看node节点
[root@swarm-manager ~]# docker node ls
ID                            HOSTNAME        STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION
mg7k04jsbu46r4oh9mssb9r1o *   swarm-manager   Ready     Active         Leader           20.10.1
eyvx9xh31vpw8tgzjfbjxrr2t     swarm-worker1   Ready     Active                          20.10.1
tiolime1uwga7g0qggf617pf0     swarm-worker2   Ready     Active                          20.10.1

# 提示节点为manager
[root@swarm-manager ~]# docker node promote swarm-worker1

# 节点降级为worker
[root@swarm-manager ~]# docker node demote swarm-worker1
```

### 3.2 图形化UI

![image-20210227152546664](https://gitee.com/luoxian1011/pictures/raw/master/image-20210227152546664.png)

```
# 部署一个图形化webUI 界面
[root@swarm-manager ~]# docker pull dockersamples/visualizer
[root@swarm-manager ~]# docker tag dockersamples/visualizer:latest 192.168.10.11:5000/visualizer
[root@swarm-manager ~]# docker push !$

# 启动容器
[root@swarm-manager ~]# docker run -d -p 8080:8080 -e HOST=172.16.0.10 -e PORT=8080 -v /var/run/docker.sock:/var/run/docker.sock --name visualizer 192.168.10.11:5000/visualizer

# 浏览器访问：http://192.168.10.11:8080/
```

### 3.3 service服务

创建好了 Swarm 集群， 现在部署⼀个运⾏ nginx 镜像的 service

```
# 创建服务，同时打开浏览器查看web界面变化
[root@swarm-manager ~]# docker service create --name web_test 192.168.10.11:5000/nginx

# 查看服务
[root@swarm-manager ~]# docker service  ls
ID             NAME       MODE         REPLICAS   IMAGE                             PORTS
00xifk81ez75   web_test   replicated   1/1        192.168.10.11:5000/nginx:latest

# REPLICAS 显示当前副本信息
# 0/1的意思是：service期望的容器副本数量为1，⽬前已经启动的副本数量为0
# 也就是当前 service 还没有部署完成。
# 命令 docker service ps 可以查看 service 每个副本的状态。
```

```
# 查看服务进程
[root@swarm-manager ~]# docker service ps web_test 
ID             NAME         IMAGE                             NODE            DESIRED STATE   CURRENT STATE            ERROR     PORTS
kgv46qlrmqgl   web_test.1   192.168.10.11:5000/nginx:latest   swarm-manager   Running         Running 40 seconds ago
```

### 3.4 service的扩容与收缩

对于 web 服务，我们通常会运⾏多个实例。这样可以负载 均衡，同时也能提供⾼可⽤。 

swarm 要实现这个⽬标⾮常简单，增加 service 的副本数就可以了

![image-20210227162846118](https://gitee.com/luoxian1011/pictures/raw/master/image-20210227162846118.png)

```
# service的扩容、收缩
# 1. 运行3个web_test
[root@swarm-manager ~]# docker service  scale  web_test=3
[root@swarm-manager ~]# docker service  ls
[root@swarm-manager ~]# docker service  ps web_test

# 2. 运行10个web_test
[root@swarm-manager ~]# docker service  scale  web_test=10

# 3. 运行1个web_test
[root@swarm-manager ~]# docker service  scale  web_test=1

# 设置某个node不运行service
# 可以通过设置，使某台节点不运行service，如下：
[root@swarm-manager ~]# docker node update --availability drain swarm-manager
```

### 3.5 Failover

故障是在所难免的，容器可能崩溃，Docker Host 可能宕机，不过幸运的是，Swarm 已经内置了 failover 策略。 

创建 service 的时候，我们没有告诉 swarm 发⽣故障时该如何处理，只是说明了我们期望的状态（⽐如 运⾏3个副本），swarm 会尽最⼤的努⼒达成这个期望状态，⽆论发⽣什么状况。

如果现在swarm-worker1、swarm-worker2发生宕机时，service并不会因为节点的宕机而死掉，而是自动跑到正常的节点上。

```
# 关闭 swarm-worker1
systemctl poweroff
```

Swarm 会检测到 swarm-node2 的故障，并标记为 Down。

```
[root@swarm-manager ~]# docker node ls
ID                            HOSTNAME        STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION
mg7k04jsbu46r4oh9mssb9r1o *   swarm-manager   Ready     Drain          Leader           20.10.1
eyvx9xh31vpw8tgzjfbjxrr2t     swarm-worker1   Down      Active                          20.10.1
tiolime1uwga7g0qggf617pf0     swarm-worker2   Ready     Active                          20.10.1
```

Swarm 会将 swarm-worker1上的副本调度到其他可⽤节点。

我们可以通过 docker service ps 观察这 个 failover 过程。

```
# 故障节点 swarm-worker1 上的副本状态被标记为 Shutdown
[root@swarm-manager ~]# docker service ps web_test 
ID             NAME             IMAGE                             NODE            DESIRED STATE   CURRENT STATE                 ERROR     PORTS
rm1uk6ep3che   web_test.1       192.168.10.11:5000/nginx:latest   swarm-worker2   Running         Running 53 seconds ago                  
li3z883icq71    \_ web_test.1   192.168.10.11:5000/nginx:latest   swarm-worker1   Shutdown        Running about a minute ago              
kgv46qlrmqgl    \_ web_test.1   192.168.10.11:5000/nginx:latest   swarm-manager   Shutdown        Shutdown about a minute ago
```

```
# 删除服务
[root@swarm-manager ~]# docker service rm web_test

# 直接创建多个副本服务
[root@swarm-manager ~]# docker service create --replicas 6 --name web -p 80:80 192.168.10.11:5000/nginx
i2ilqgbykroyc5alh7w43c0db
overall progress: 6 out of 6 tasks 
1/6: running   
2/6: running   
3/6: running   
4/6: running   
5/6: running   
6/6: running   
verify: Service converged
//--replicas: 指定副本数量副本指的也就是容器。
```

### 3.6 发布端口服务

```
# 发布服务
# docker service update --publish-add + 端口 + 服务
# 会先将现有容器删除，再重新创建新容器
[root@swarm-manager ~]# docker service update --publish-add 9999:80 web
# 访问测试
[root@swarm-manager ~]# curl swarm-manager:9999
[root@swarm-manager ~]# curl swarm-worker1:9999
[root@swarm-manager ~]# curl swarm-worker2:9999
```

```
# 创建服务直接发布端口
# --publish 7777:80
[root@swarm-manager ~]# docker service create --replicas 6  --name web --publish 7777:80 192.168.10.11:5000/nginx
# 访问测试
[root@swarm-manager ~]# curl swarm-manager:7777
```

## 4. 网络

### 4.1 ingress网络

通过 Ingress 模式发布的服务，可以保证从 Swarm 集群内任一节点（即使没有运行服务的副本）都能访问该服务；

```
# 创建服务web_test1，共2个副本
[root@swarm-manager ~]# docker service create --name web_test1 --replicas 2 192.168.10.11:5000/nginx

# 查看容器信息
[root@swarm-worker1 ~]# docker inspect web_test1.2.mgsorol8ne2vlg6c70r47fyl8

# 更新发布端口
# 容器会一个一个重新启动
[root@swarm-manager ~]# docker service update --publish-add 9999:80 web_test1

# 扩展5个容器
[root@swarm-manager ~]# docker service scale web_test1=5

# 创建一个共享web_test1网络的容器
[root@swarm-worker1 ~]# docker run -dit --name test1 --network container:web_test1.2.kngd1k21yfeo56llb70o83zy6 192.168.10.11:5000/busybox
[root@swarm-worker1 ~]# docker exec -it test1 sh
/ # ip a
# eth0：ingress - overlay网络 - 让运行在不同主机的容器互相通信
# eth1：docker_gwbridge - bridge网络 - 让容器访问外网
inet 127.0.0.1/8 scope host lo
inet 10.0.0.12/24 brd 10.0.0.255 scope global eth0
inet 172.18.0.3/16 brd 172.18.255.255 scope global eth1

# 查看网络
[root@swarm-manager ~]# docker network ls
NETWORK ID     NAME              DRIVER    SCOPE
14d30848f313   bridge            bridge    local
806d0d5c2b4b   docker_gwbridge   bridge    local
2664f5be1a1f   host              host      local
f3yzu2cpssmw   ingress           overlay   swarm
a20992b07474   none              null      local

# 查看ingress网络[10.0.0.14/24]，对应容器的eth0接口
# 集群中的节点都在 Peers组里，所有节点都可以访问服务
[root@swarm-worker1 ~]# docker inspect ingress

[root@swarm-manager ~]# docker service rm web_test1
```

### 4.2 服务互联

如果将所有service都publish出去，缺点很明显：mysql等重要服务也暴露到外网，增加了安全隐患

Docker Swarm 原生提供服务发现：

通过服务发现，service的使用者不需要知道service运行在哪里，ip多少，有多少副本，就能与service通信

```
# 服务之间的互联

# 创建网络myoverlay
[root@swarm-manager ~]# docker network create -d overlay myoverlay
o4qiyujs81yg9h7hzubj2kg43
[root@swarm-manager ~]# docker network ls
NETWORK ID     NAME              DRIVER    SCOPE
14d30848f313   bridge            bridge    local
806d0d5c2b4b   docker_gwbridge   bridge    local
2664f5be1a1f   host              host      local
f3yzu2cpssmw   ingress           overlay   swarm
o4qiyujs81yg   myoverlay         overlay   swarm
a20992b07474   none              null      local

# 创建服务
[root@swarm-manager ~]# docker service create --name my_web1 --replicas 3 --network myoverlay 192.168.10.11:5000/nginx

# 创建测试服务
# sleep 1000000000，否则容器创建直接退出
[root@swarm-manager ~]# docker service create --name test1 --network myoverlay 192.168.10.11:5000/busybox sleep 1000000000

# 使用test容器 ping my_web1容器
# 可以ping通 同主机或跨主机都可以
[root@swarm-worker2 ~]# docker exec test1.1.4vrg0wyq5nht3jslwulb2x380 ping -c 3 my_web1.2.bps026tp517dhqcolv29lut4n
[root@swarm-worker2 ~]# docker exec test1.1.4vrg0wyq5nht3jslwulb2x380 ping -c 3 my_web1.1.sw2vi7t4deh6ob0tfe9nphgfn
# 也可以ping通服务名 my_web1 
# pign的是vip
[root@swarm-worker2 ~]# docker exec test1.1.4vrg0wyq5nht3jslwulb2x380 ping -c 3 my_web1

[root@swarm-manager ~]# docker service rm test1 my_web1
```

## 5. 滚动更新

Docker Swarm可以实现服务平滑升级，即服务不停机更新，客户端无感知。

```
# 滚动更新

# 下载镜像
[root@swarm-manager ~]# docker pull httpd:2.4.46
[root@swarm-manager ~]# docker pull httpd:2.4.43
[root@swarm-manager ~]# docker pull httpd:2.2.34
# 打上私有仓库标签
docker tag httpd:2.4.46 192.168.10.11:5000/httpd:2.4.46
docker tag httpd:2.4.43 192.168.10.11:5000/httpd:2.4.43
docker tag httpd:2.2.34 192.168.10.11:5000/httpd:2.2.34
# 上传到私有仓库
docker push 192.168.10.11:5000/httpd:2.4.46
docker push 192.168.10.11:5000/httpd:2.4.43
docker push 192.168.10.11:5000/httpd:2.2.34

# 运行一个容器测试，查看版本
[root@swarm-manager ~]# docker run -dit --name test1 192.168.10.11:5000/httpd:2.4.46 
[root@swarm-manager ~]# docker exec test1 apachectl -v
[root@swarm-manager ~]# docker rm -f test1 

# 启动服务版本：2.4.43
[root@swarm-manager ~]# docker service create --name web-http --replicas 3 192.168.10.11:5000/httpd:2.4.43 

# 更新升级[2.4.46] -> 服务镜像
[root@swarm-manager ~]# docker service update --image 192.168.10.11:5000/httpd:2.4.46 web-http 
# 查看进程信息[过程是一个一个重启]
[root@swarm-manager ~]# docker service ps web-http 
ID             NAME             IMAGE                             NODE            DESIRED STATE   CURRENT STATE             ERROR     PORTS
x36tyw68pgj0   web-http.1       192.168.10.11:5000/httpd:2.4.46   swarm-worker2   Running         Running 32 seconds ago              
a8qf9q1ymfpw    \_ web-http.1   192.168.10.11:5000/httpd:2.4.43   swarm-worker2   Shutdown        Shutdown 33 seconds ago             
lhb5nnvoa3ew   web-http.2       192.168.10.11:5000/httpd:2.4.46   swarm-worker1   Running         Running 30 seconds ago              
efn8ntrr982c    \_ web-http.2   192.168.10.11:5000/httpd:2.4.43   swarm-worker1   Shutdown        Shutdown 30 seconds ago             
qu7vkbohfwgp   web-http.3       192.168.10.11:5000/httpd:2.4.46   swarm-worker1   Running         Running 36 seconds ago              
06hz96tw9h3u    \_ web-http.3   192.168.10.11:5000/httpd:2.4.43   swarm-worker2   Shutdown        Shutdown 38 seconds ago  


[root@swarm-manager ~]# docker update --help
# 更新延时
--update-delay duration              Delay between updates (ns|us|ms|s|m|h)
# 同时更新节点数
--update-parallelism uint            Maximum number of tasks updated simultaneously
# 回滚到前一个版本
--rollback                           Rollback to previous specification

# 将manager的排除去掉，也运行容器
[root@swarm-manager ~]# docker node update --availability active swarm-manager 
# 更新配置
# --update-delay 1m30s 
# --update-parallelism 2
[root@swarm-manager ~]# docker service update --replicas 6 --update-delay 1m30s --update-parallelism 2 web-http 

# 此时更新[2.2.34]，会同时更新2个，且有延时1m30s
[root@swarm-manager ~]# docker service update --image 192.168.10.11:5000/httpd:2.2.34 web-http 
1/6: running   
2/6: running   
3/6:    
4/6:    
5/6:    
6/6: 
# 完成后，查看进程
[root@swarm-manager ~]# docker service ps web-http 

# 回归版本[回到2.4.46]
[root@swarm-manager ~]# docker service update --rollback web-http
```

## 6. global模式

service模式：

1. replicated[默认]：可以通过--replicas指定副本数
2. global：强制在每个node上只运行一个副本，适合需要daemon的集群环境。

比如要Prometheus 收集所有容器的日志，使用global模式可以使所有节点都运行Node-exporter容器，之后新加入的node也会自动启动Node-exporter容器

```

# 每个节点只部署一个容器
# --mode global
[root@swarm-manager ~]# docker service create --name test1 --mode global 192.168.10.11:5000/nginx 

# 排除swarm-manager，其他节点容器不变
[root@swarm-manager ~]# docker node update --availability drain swarm-manager 

```

## 7. 节点标签约束

使用Label控制Service的位置

lable可以灵活的描述node属性，其形式是key=value，可以任意指定

例如：env=test

1. 为每个node定义label
2. 设置service运行在指定label的node上

```
# 打标签 --label-add
# 标签为键值对 env=test
# 将swarm-worker1 打上 测试组标签
[root@swarm-manager ~]# docker node update --label-add env=test swarm-worker1 
swarm-worker1

# 可以使用inspect查看标签
[root@swarm-manager ~]# docker node inspect swarm-worker1 

# 打标签 
# 将swarm-worker2 打上 发布组标签
# env=prod
[root@swarm-manager ~]# docker node update --label-add env=prod swarm-worker2

# 创建服务，并约束在env==test节点
[root@swarm-manager ~]# docker service create --constraint node.labels.env==test --replicas 10 --name my_test1 192.168.10.11:5000/nginx
# --constraint 约束
# node.labels.env==test 限制在标签节点

# 查看约束，Placement
[root@swarm-manager ~]# docker service inspect my_test1 --pretty 
Placement:
 Constraints:	[node.labels.env==test]
 
# 删除约束
[root@swarm-manager ~]# docker service update --constraint-rm node.labels.env==test my_test1

# 迁移容器，将test节点的容器迁移到prod节点（类似测试与发布）
[root@swarm-manager ~]# docker service update --constraint-add node.labels.env==prod my_test1

```

