# Docker Swarm

## 1. 概念

**docker-swarm是解决多主机多个容器调度部署得问题。**
Swarm是Docker 引擎内置（原生）的集群管理和编排工具。Docker Swarm是 Docker 官方三剑客项目之一，swarm是基于docker平台实现的集群技术，他可以通过几条简单的指令快速的创建一个docker集群，接着在集群的共享网络上部署应用，最终实现分布式的服务。

**Docker swarm中有三种角色：**

- **manager node:** 负责执行容器的编排和集群的管理工作，保持并维护swarm处于期望的状态。swarm可以有多个manager node，他们会自动协调并选举出一个Leader执行编排任务。但相反，不能没有managernode。
- **worker node:** 接受并执行由manager node 派发的任务，并且默认manager node也是一个work node，不过可以将它设置为manager-onlynode.让它只负责编排和管理工作。
- **service:** 用来定义worker上执行的命令。

**Swarm命令行说明**：

```
docker swarm：集群管理
init          #初始化集群
join          #将节点加入集群
join-token    #管理加入令牌
leave         #从集群中删除某个节点，强制删除加参数--force 
update        #更新集群
unlock        #解锁集群
```

```
docker node：节点管理，
demote      #将集群中一个或多个节点降级
inspect     #显示一个或多个节点的详细信息
ls          #列出集群中的节点
promote     #将一个或多个节点提升为管理节点
rm          #从集群中删除停止的节点，--force强制删除参数
ps          #列出一个或多个节点上运行的任务
update      #更新节点
```

```
docker service：服务管理，
create      #创建一个新的服务
inspect     #列出一个或多个服务的详细信息
ps          #列出一个或多个服务中的任务信息
ls          #列出服务
rm          #删除一个或多个服务
scale       #扩展一个或多个服务
update      #更新服务
```

## 2. 准备环境

### 2.1 实验拓扑

[基础为docker环境]

|     主机      |      IP       |  角色   |
| :-----------: | :-----------: | :-----: |
| swarm-manager | 192.168.10.11 | manager |
| swarm-worker1 | 192.168.10.12 | worker  |
| swarm-worker2 | 192.168.10.13 | worker  |

```
# 修改hosts文件
vim /etc/hosts

192.168.10.11 swarm-manager
192.168.10.12 swarm-worker1
192.168.10.13 swarm-worker2
```

```
# 关闭selinux
sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config

# 开启防火墙端口
# 2377/tcp（管理端口）
# 7946/udp（节点间通信端口）
# 4789/udp（overlay 网络端口）
firewall-cmd --add-port={2377,4789,7946}/tcp --permanent
firewall-cmd --add-port={4789,7946}/udp --permanent
firewall-cmd --reload
```

### 2.2 搭建私有仓库

在swarm-manager上操作

```
# 准备docker镜像
docker pull nginx
docker pull centos
docker pull busybox
docker pull registry # 私有仓库
```

```
# 启动registry
[root@swarm-manager ~]# docker run -dit --name registry -p 5000:5000 -v /var/registry:/var/lib/registry --restart always registry

# 查看查看镜像
[root@swarm-manager ~]# curl 192.168.10.11:5000/v2/_catalog
{"repositories":[]}

# 添加配置
vi /etc/docker/daemon.json
{
"registry-mirrors":[
        "https://8p2ftmks.mirror.aliyuncs.com"
    ],
"insecure-registries": [
        "192.168.10.11:5000"
    ]
}

# 重启docker
sudo systemctl   daemon-reload
systemctl restart docker.service
docker info
```

```
# 打上私有仓库的标签
[root@swarm-manager ~]# docker tag busybox:latest 192.168.10.11:5000/busybox
[root@swarm-manager ~]# docker tag nginx:latest 192.168.10.11:5000/nginx
[root@swarm-manager ~]# docker tag centos:latest 192.168.10.11:5000/centos

# 上传到私有仓库
[root@swarm-manager ~]# docker push 192.168.10.11:5000/busybox
[root@swarm-manager ~]# docker push 192.168.10.11:5000/nginx
[root@swarm-manager ~]# docker push 192.168.10.11:5000/centos

# 查看仓库镜像
[root@swarm-manager ~]# curl 192.168.10.11:5000/v2/_catalog
{"repositories":["busybox","centos","nginx"]}
```

### 2.3 ssh无密连接

```
# 三台之间，无密互联
# 生成密钥
[root@swarm-manager ~]# ssh-keygen -t rsa
# 拷贝到其他节点
[root@swarm-manager ~]# ssh-copy-id swarm-worker1
[root@swarm-manager ~]# ssh-copy-id swarm-worker2

# ssh swarm-worker1
# ssh-keygen -t rsa
# ssh-copy-id swarm-manager
# ssh-copy-id swarm-worker2

# ssh swarm-worker2
# ssh-keygen -t rsa
# ssh-copy-id swarm-manager
# ssh-copy-id swarm-worker1
# 退出，返回到swarm-manager
```

```
# 就docker的配置文件拷贝[私有仓库配置信息]
[root@swarm-manager ~]# scp /etc/docker/daemon.json swarm-worker1:/etc/docker/
[root@swarm-manager ~]# scp /etc/docker/daemon.json swarm-worker2:/etc/docker/
# 在其他节点重启docker
sudo systemctl   daemon-reload
systemctl restart docker.service
# 检查私有仓库地址是否正确
docker info
```

## 3. swarm集群

### 3.1 swarm初始化

```
# 初始化swarm集群
# --advertise-addr 指定与其他 node 通信的地址
# 会生成加入节点的命令：docker swarm join --token...
[root@swarm-manager ~]# docker swarm init --advertise-addr 192.168.10.11
```

docker swarm init 输出告诉我们： 

1. swarm 创建成功，swarm-manager 成为 manager node。 
2. 添加 worker node 需要执⾏的命令。 
3. 添加 manager node 需要执⾏的命令。 

```
# 查看集群的节点
[root@swarm-manager ~]# docker node  ls

# 复制前⾯的 docker swarm join 命令
# 在其他节点加入集群，在swarm-node2和swarm-node3上执行
docker swarm join --token SWMTKN-1-2sztfer3ifyrio1tmhlla6tsgbo0f2m0pks2sk4hs16cbwg9rd-1h1uvp5rabutkyu5ev4jix3t4 192.168.10.11:2377

# 显示 token值，此命令只能在 manager node 上执⾏
[root@swarm-manager ~]# docker swarm join-token worker
[root@swarm-manager ~]# docker swarm join-token manager

# 查看node节点
[root@swarm-manager ~]# docker node ls
ID                            HOSTNAME        STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION
mg7k04jsbu46r4oh9mssb9r1o *   swarm-manager   Ready     Active         Leader           20.10.1
eyvx9xh31vpw8tgzjfbjxrr2t     swarm-worker1   Ready     Active                          20.10.1
tiolime1uwga7g0qggf617pf0     swarm-worker2   Ready     Active                          20.10.1

# 提示节点为manager
[root@swarm-manager ~]# docker node promote swarm-worker1

# 节点降级为worker
[root@swarm-manager ~]# docker node demote swarm-worker1
```

### 3.2 图形化UI

![image-20210227152546664](https://gitee.com/luoxian1011/pictures/raw/master/image-20210227152546664.png)

```
# 部署一个图形化webUI 界面
[root@swarm-manager ~]# docker pull dockersamples/visualizer
[root@swarm-manager ~]# docker tag dockersamples/visualizer:latest 192.168.10.11:5000/visualizer
[root@swarm-manager ~]# docker push !$

# 启动容器
[root@swarm-manager ~]# docker run -d -p 8080:8080 -e HOST=172.16.0.10 -e PORT=8080 -v /var/run/docker.sock:/var/run/docker.sock --name visualizer 192.168.10.11:5000/visualizer

# 浏览器访问：http://192.168.10.11:8080/
```

### 3.3 service服务

创建好了 Swarm 集群， 现在部署⼀个运⾏ nginx 镜像的 service

```
# 创建服务，同时打开浏览器查看web界面变化
[root@swarm-manager ~]# docker service create --name web_test 192.168.10.11:5000/nginx

# 查看服务
[root@swarm-manager ~]# docker service  ls
ID             NAME       MODE         REPLICAS   IMAGE                             PORTS
00xifk81ez75   web_test   replicated   1/1        192.168.10.11:5000/nginx:latest

# REPLICAS 显示当前副本信息
# 0/1的意思是：service期望的容器副本数量为1，⽬前已经启动的副本数量为0
# 也就是当前 service 还没有部署完成。
# 命令 docker service ps 可以查看 service 每个副本的状态。
```

```
# 查看服务进程
[root@swarm-manager ~]# docker service ps web_test 
ID             NAME         IMAGE                             NODE            DESIRED STATE   CURRENT STATE            ERROR     PORTS
kgv46qlrmqgl   web_test.1   192.168.10.11:5000/nginx:latest   swarm-manager   Running         Running 40 seconds ago
```

### 3.4 service的扩容与收缩

对于 web 服务，我们通常会运⾏多个实例。这样可以负载 均衡，同时也能提供⾼可⽤。 

swarm 要实现这个⽬标⾮常简单，增加 service 的副本数就可以了

![image-20210227162846118](https://gitee.com/luoxian1011/pictures/raw/master/image-20210227162846118.png)

```
# service的扩容、收缩
# 1. 运行3个web_test
[root@swarm-manager ~]# docker service  scale  web_test=3
[root@swarm-manager ~]# docker service  ls
[root@swarm-manager ~]# docker service  ps web_test

# 2. 运行10个web_test
[root@swarm-manager ~]# docker service  scale  web_test=10

# 3. 运行1个web_test
[root@swarm-manager ~]# docker service  scale  web_test=1

# 设置某个node不运行service
# 可以通过设置，使某台节点不运行service，如下：
[root@swarm-manager ~]# docker node update --availability drain swarm-manager
```

### 3.5 Failover

故障是在所难免的，容器可能崩溃，Docker Host 可能宕机，不过幸运的是，Swarm 已经内置了 failover 策略。 

创建 service 的时候，我们没有告诉 swarm 发⽣故障时该如何处理，只是说明了我们期望的状态（⽐如 运⾏3个副本），swarm 会尽最⼤的努⼒达成这个期望状态，⽆论发⽣什么状况。

如果现在swarm-worker1、swarm-worker2发生宕机时，service并不会因为节点的宕机而死掉，而是自动跑到正常的节点上。

```
# 关闭 swarm-worker1
systemctl poweroff
```

Swarm 会检测到 swarm-node2 的故障，并标记为 Down。

```
[root@swarm-manager ~]# docker node ls
ID                            HOSTNAME        STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION
mg7k04jsbu46r4oh9mssb9r1o *   swarm-manager   Ready     Drain          Leader           20.10.1
eyvx9xh31vpw8tgzjfbjxrr2t     swarm-worker1   Down      Active                          20.10.1
tiolime1uwga7g0qggf617pf0     swarm-worker2   Ready     Active                          20.10.1
```

Swarm 会将 swarm-worker1上的副本调度到其他可⽤节点。

我们可以通过 docker service ps 观察这 个 failover 过程。

```
# 故障节点 swarm-worker1 上的副本状态被标记为 Shutdown
[root@swarm-manager ~]# docker service ps web_test 
ID             NAME             IMAGE                             NODE            DESIRED STATE   CURRENT STATE                 ERROR     PORTS
rm1uk6ep3che   web_test.1       192.168.10.11:5000/nginx:latest   swarm-worker2   Running         Running 53 seconds ago                  
li3z883icq71    \_ web_test.1   192.168.10.11:5000/nginx:latest   swarm-worker1   Shutdown        Running about a minute ago              
kgv46qlrmqgl    \_ web_test.1   192.168.10.11:5000/nginx:latest   swarm-manager   Shutdown        Shutdown about a minute ago
```

```
# 删除服务
[root@swarm-manager ~]# docker service rm web_test

# 直接创建多个副本服务
[root@swarm-manager ~]# docker service create --replicas 6 --name web -p 80:80 192.168.10.11:5000/nginx
i2ilqgbykroyc5alh7w43c0db
overall progress: 6 out of 6 tasks 
1/6: running   
2/6: running   
3/6: running   
4/6: running   
5/6: running   
6/6: running   
verify: Service converged
//--replicas: 指定副本数量副本指的也就是容器。
```

### 3.6 发布端口服务

```
# 发布服务
# docker service update --publish-add + 端口 + 服务
# 会先将现有容器删除，再重新创建新容器
[root@swarm-manager ~]# docker service update --publish-add 9999:80 web
# 访问测试
[root@swarm-manager ~]# curl swarm-manager:9999
[root@swarm-manager ~]# curl swarm-worker1:9999
[root@swarm-manager ~]# curl swarm-worker2:9999
```

```
# 创建服务直接发布端口
# --publish 7777:80
[root@swarm-manager ~]# docker service create --replicas 6  --name web --publish 7777:80 192.168.10.11:5000/nginx
# 访问测试
[root@swarm-manager ~]# curl swarm-manager:7777
```

## 4. 网络

### 4.1 ingress网络

通过 Ingress 模式发布的服务，可以保证从 Swarm 集群内任一节点（即使没有运行服务的副本）都能访问该服务；

```
# 创建服务web_test1，共2个副本
[root@swarm-manager ~]# docker service create --name web_test1 --replicas 2 192.168.10.11:5000/nginx

# 在swarm-worker1上查看容器信息
[root@swarm-worker1 ~]# docker inspect web_test1.2.mgsorol8ne2vlg6c70r47fyl8

# 更新发布端口
# 容器会一个一个重新启动
[root@swarm-manager ~]# docker service update --publish-add 9999:80 web_test1

# 扩展5个容器
[root@swarm-manager ~]# docker service scale web_test1=5

# 在swarm-worker1上创建一个共享web_test1网络的容器
[root@swarm-worker1 ~]# docker run -dit --name test1 --network container:web_test1.2.kngd1k21yfeo56llb70o83zy6 192.168.10.11:5000/busybox
[root@swarm-worker1 ~]# docker exec -it test1 sh
/ # ip a
# eth0：ingress - overlay网络 - 让运行在不同主机的容器互相通信
# eth1：docker_gwbridge - bridge网络 - 让容器访问外网
inet 127.0.0.1/8 scope host lo
inet 10.0.0.12/24 brd 10.0.0.255 scope global eth0
inet 172.18.0.3/16 brd 172.18.255.255 scope global eth1

# 查看网络
[root@swarm-manager ~]# docker network ls
NETWORK ID     NAME              DRIVER    SCOPE
14d30848f313   bridge            bridge    local
806d0d5c2b4b   docker_gwbridge   bridge    local
2664f5be1a1f   host              host      local
f3yzu2cpssmw   ingress           overlay   swarm
a20992b07474   none              null      local

# 查看ingress网络[10.0.0.0/24]，对应容器的eth0接口
# 集群中的节点都在 Peers组里，所有节点都可以访问服务
[root@swarm-worker1 ~]# docker inspect ingress

[root@swarm-manager ~]# docker service rm web_test1
```

### 4.2 服务互联

如果将所有service都publish出去，缺点很明显：mysql等重要服务也暴露到外网，增加了安全隐患

Docker Swarm 原生提供服务发现：

通过服务发现，service的使用者不需要知道service运行在哪里，ip多少，有多少副本，就能与service通信

```
# 服务之间的互联

# 创建网络myoverlay
[root@swarm-manager ~]# docker network create -d overlay myoverlay
o4qiyujs81yg9h7hzubj2kg43
[root@swarm-manager ~]# docker network ls
NETWORK ID     NAME              DRIVER    SCOPE
14d30848f313   bridge            bridge    local
806d0d5c2b4b   docker_gwbridge   bridge    local
2664f5be1a1f   host              host      local
f3yzu2cpssmw   ingress           overlay   swarm
o4qiyujs81yg   myoverlay         overlay   swarm
a20992b07474   none              null      local

# 创建服务
[root@swarm-manager ~]# docker service create --name my_web1 --replicas 3 --network myoverlay 192.168.10.11:5000/nginx

# 创建测试服务，创建完成后查看在哪个节点，然后测试
# sleep 1000000000，否则容器创建直接退出
[root@swarm-manager ~]# docker service create --name test1 --network myoverlay 192.168.10.11:5000/busybox sleep 1000000000

# 使用test容器 ping my_web1容器
# 可以ping通 同主机或跨主机都可以
[root@swarm-worker2 ~]# docker exec test1.1.4vrg0wyq5nht3jslwulb2x380 ping -c 3 my_web1.2.bps026tp517dhqcolv29lut4n
[root@swarm-worker2 ~]# docker exec test1.1.4vrg0wyq5nht3jslwulb2x380 ping -c 3 my_web1.1.sw2vi7t4deh6ob0tfe9nphgfn
# 也可以ping通服务名 my_web1 
# pign的是vip
[root@swarm-worker2 ~]# docker exec test1.1.4vrg0wyq5nht3jslwulb2x380 ping -c 3 my_web1

[root@swarm-manager ~]# docker service rm test1 my_web1
```

## 5. 滚动更新

Docker Swarm可以实现服务平滑升级，即服务不停机更新，客户端无感知。

```
# 滚动更新

# 下载镜像
[root@swarm-manager ~]# docker pull httpd:2.4.46
[root@swarm-manager ~]# docker pull httpd:2.4.43
[root@swarm-manager ~]# docker pull httpd:2.2.34
# 打上私有仓库标签
docker tag httpd:2.4.46 192.168.10.11:5000/httpd:2.4.46
docker tag httpd:2.4.43 192.168.10.11:5000/httpd:2.4.43
docker tag httpd:2.2.34 192.168.10.11:5000/httpd:2.2.34
# 上传到私有仓库
docker push 192.168.10.11:5000/httpd:2.4.46
docker push 192.168.10.11:5000/httpd:2.4.43
docker push 192.168.10.11:5000/httpd:2.2.34

# 运行一个容器测试，查看版本
[root@swarm-manager ~]# docker run -dit --name test1 192.168.10.11:5000/httpd:2.4.46 
[root@swarm-manager ~]# docker exec test1 apachectl -v
[root@swarm-manager ~]# docker rm -f test1 

# 启动服务版本：2.4.43
[root@swarm-manager ~]# docker service create --name web-http --replicas 3 192.168.10.11:5000/httpd:2.4.43 

# 更新升级[2.4.46] -> 服务镜像
# update --image
[root@swarm-manager ~]# docker service update --image 192.168.10.11:5000/httpd:2.4.46 web-http 
# 查看进程信息[过程是一个一个重启]
[root@swarm-manager ~]# docker service ps web-http 
ID             NAME             IMAGE                             NODE            DESIRED STATE   CURRENT STATE             ERROR     PORTS
x36tyw68pgj0   web-http.1       192.168.10.11:5000/httpd:2.4.46   swarm-worker2   Running         Running 32 seconds ago              
a8qf9q1ymfpw    \_ web-http.1   192.168.10.11:5000/httpd:2.4.43   swarm-worker2   Shutdown        Shutdown 33 seconds ago             
lhb5nnvoa3ew   web-http.2       192.168.10.11:5000/httpd:2.4.46   swarm-worker1   Running         Running 30 seconds ago              
efn8ntrr982c    \_ web-http.2   192.168.10.11:5000/httpd:2.4.43   swarm-worker1   Shutdown        Shutdown 30 seconds ago             
qu7vkbohfwgp   web-http.3       192.168.10.11:5000/httpd:2.4.46   swarm-worker1   Running         Running 36 seconds ago              
06hz96tw9h3u    \_ web-http.3   192.168.10.11:5000/httpd:2.4.43   swarm-worker2   Shutdown        Shutdown 38 seconds ago  


[root@swarm-manager ~]# docker update --help
# 更新延时
--update-delay duration              Delay between updates (ns|us|ms|s|m|h)
# 同时更新节点数
--update-parallelism uint            Maximum number of tasks updated simultaneously
# 回滚到前一个版本
--rollback                           Rollback to previous specification

# 将manager的排除去掉，也运行容器
[root@swarm-manager ~]# docker node update --availability active swarm-manager 
# 更新配置
# --update-delay 1m30s 
# --update-parallelism 2
[root@swarm-manager ~]# docker service update --replicas 6 --update-delay 1m30s --update-parallelism 2 web-http 

# 此时更新[2.2.34]，会同时更新2个，且有延时1m30s
[root@swarm-manager ~]# docker service update --image 192.168.10.11:5000/httpd:2.2.34 web-http 
1/6: running   
2/6: running   
3/6:    
4/6:    
5/6:    
6/6: 
# 完成后，查看进程
[root@swarm-manager ~]# docker service ps web-http 

# 回归版本[回到2.4.46]，只能退回上一次版本
[root@swarm-manager ~]# docker service update --rollback web-http
```

## 6. global模式

service模式：

1. replicated[默认]：可以通过--replicas指定副本数
2. global：强制在每个node上只运行一个副本，适合需要daemon的集群环境。

比如要Prometheus 收集所有容器的日志，使用global模式可以使所有节点都运行Node-exporter容器，之后新加入的node也会自动启动Node-exporter容器

```

# 每个节点只部署一个容器
# --mode global
[root@swarm-manager ~]# docker service create --name test1 --mode global 192.168.10.11:5000/nginx 

# 排除swarm-manager，其他节点容器不变
[root@swarm-manager ~]# docker node update --availability drain swarm-manager 

```

## 7. 节点标签约束

使用Label控制Service的位置

lable可以灵活的描述node属性，其形式是key=value，可以任意指定

例如：env=test

1. 为每个node定义label
2. 设置service运行在指定label的node上

```
# 打标签 --label-add；删除标签--label-rm
# 标签为键值对 env=test
# 将swarm-worker1 打上 测试组标签
[root@swarm-manager ~]# docker node update --label-add env=test swarm-worker1 
swarm-worker1

# 可以使用inspect查看标签
[root@swarm-manager ~]# docker node inspect swarm-worker1 

# 打标签 
# 将swarm-worker2 打上 发布组标签
# env=prod
[root@swarm-manager ~]# docker node update --label-add env=prod swarm-worker2

# 创建服务，并约束在env==test节点
[root@swarm-manager ~]# docker service create --constraint node.labels.env==test --replicas 10 --name my_test1 192.168.10.11:5000/nginx
# --constraint 约束
# node.labels.env==test 限制在标签节点

# 查看约束，Placement
[root@swarm-manager ~]# docker service inspect my_test1 --pretty 
Placement:
 Constraints:	[node.labels.env==test]
 
# 删除约束
[root@swarm-manager ~]# docker service update --constraint-rm node.labels.env==test my_test1

# 迁移容器，将test节点的容器迁移到prod节点（类似测试与发布）
[root@swarm-manager ~]# docker service update --constraint-add node.labels.env==prod my_test1

```

## 8. 健康检查

### 8.1 创建nginx镜像

```
# 制作nginx镜像
[root@swarm-manager ~]# mkdir mynginx
[root@swarm-manager ~]# cd mynginx/
[root@swarm-manager mynginx]# echo test_page > index.html 
[root@swarm-manager mynginx]# vim Dockerfile 

# Dockerfile内容：制作nginx镜像
FROM 192.168.10.11:5000/centos
RUN yum install -y epel-release
RUN yum install -y nginx
ADD index.html /usr/share/nginx/html
EXPOSE 80
ENTRYPOINT [ "nginx", "-g", "daemon off;" ]

# 构建镜像并启动
[root@swarm-manager mynginx]# docker build -t 192.168.10.11:5000/mynginx .
[root@swarm-manager mynginx]# docker run -dit --name mynginx -p 80 192.168.10.11:5000/mynginx
# 测试访问
[root@swarm-manager mynginx]# curl localhost:49153
# 上传到私有仓库
[root@swarm-manager mynginx]# docker push 192.168.10.11:5000/mynginx

```

### 8.2 健康检测参数

```
# 监控检测参数
--health-cmd string              检测健康状态的命令
--health-interval duration       命令执行的间隔 默认0s
--health-retries int             命令失败重试的次数，默认为3 如果3次都失败了则会将容器标记为unhealthy swarm 会销毁并重建unhealthy的副本
--health-timeout duration        命令超时的时间 默认0s
```

容器：

```
# 附加监控监测启动
# 检测命令：curl -f http://localhost || exit 1
[root@swarm-manager mynginx]# docker run -dit --name mynginx1 -p 80 --health-cmd "curl -f http://localhost || exit 1" --health-timeout 5s --health-interval 10s --health-retries 3   192.168.10.11:5000/mynginx
# 查看容器状态
[root@swarm-manager mynginx]# docker ps
CONTAINER ID   IMAGE                           COMMAND                  CREATED              STATUS                        PORTS                    NAMES
acdb37160ec2   192.168.10.11:5000/mynginx      "nginx -g 'daemon of…"   14 seconds ago       Up 13 seconds (healthy)       0.0.0.0:49155->80/tcp    mynginx1

```

```
# 模拟不健康的场景
# 检测命令：curl -f http://localhost/nopage || exit 1
[root@swarm-manager mynginx]# docker run -dit --name mynginx2 -p 80 --health-cmd "curl -f http://localhost/nopage || exit 1" --health-timeout 5s --health-interval 10s --health-retries 3   192.168.10.11:5000/mynginx
[root@swarm-manager mynginx]# docker ps 
CONTAINER ID   IMAGE                           COMMAND                  CREATED          STATUS                      PORTS                    NAMES
501859f2c67b   192.168.10.11:5000/mynginx      "nginx -g 'daemon of…"   16 minutes ago   Up 16 minutes (unhealthy)   0.0.0.0:49156->80/tcp    mynginx2

```

服务：

```
# 启动服务，附加健康检测参数
[root@swarm-manager mynginx]# docker service create --name myweb1 --publish 80:80 --health-cmd "curl -f http://localhost || exit 1" --health-timeout 5s --health-interval 5s --health-retries 3 --replicas 3 192.168.10.11:5000/mynginx

# 去容器节点查看
[root@swarm-worker1 ~]# docker ps 
CONTAINER ID   IMAGE                               COMMAND                  CREATED              STATUS                        PORTS     NAMES
18c053c35af2   192.168.10.11:5000/mynginx:latest   "nginx -g 'daemon of…"   About a minute ago   Up About a minute (healthy)   80/tcp    myweb1.2.q567cvhc28reh6eh6n2mjcosz

```

```
# 当启动服务时，健康检测失败，会重复尝试启动
[root@swarm-manager mynginx]# docker service create --name myweb1 --publish 80:80 --health-cmd "curl -f http://localhost/nopage || exit 1" --health-timeout 5s --health-interval 5s --health-retries 3 192.168.10.11:5000/mynginx
spdygjni35fr4mp9gx04yleup
overall progress: 0 out of 1 tasks 
1/1: starting  [============================================>      ] 

```

## 9. secret

我们经常要向容器传递敏感信息，常见的莫过于密码。

  在启动mysql容器时我们通过环境变量mysql_root_password设置了mysql的管理员密码。，不过密码是以明文的形式写在docker run 命令中，有潜在的安全隐患。

 为了解决这个问题，docker swarm提供了secret机制，允许将敏感信息加密后保存到secret中，用户可以指定哪些容器可以使用此secret。

  secret可用于管理：

1. 用户名和密码

2. TLS证书

3. ssh秘钥

4. 其他小于500kb的数据。

```
# 下载mysql镜像
[root@swarm-manager mynginx]# docker pull mysql:5.7
# 上传到私有仓库
[root@swarm-manager mynginx]# docker tag mysql:5.7 192.168.10.11:5000/mysql
[root@swarm-manager mynginx]# docker push !$
# 正常启动mysql容器
# MYSQL_ROOT_PASSWORD=123 指定root密码
[root@swarm-manager mynginx]# docker run -dit --name db1 -e MYSQL_ROOT_PASSWORD=123 mysql:5.7 

```

### 9.1 创建secret

```
# 创建secret[使用输入流创建]
[root@swarm-manager mynginx]# echo "password" | docker secret create my_secret1 -
vhv3x8hjw1af64z7ienk32cpm
# 创建secret[使用文件创建]
[root@swarm-manager mynginx]# openssl rand -base64 10 > password.txt
[root@swarm-manager mynginx]# docker secret create mypwd password.txt 

# 生成随机值
[root@swarm-manager mynginx]# openssl rand -base64 10
[root@swarm-manager mynginx]# openssl rand -base64 10 | docker secret create mysql_root_password -

# 查看secret列表
[root@swarm-manager mynginx]# docker secret ls
ID                          NAME         DRIVER    CREATED          UPDATED
vhv3x8hjw1af64z7ienk32cpm   my_secret1             13 seconds ago   13 seconds ago
# 查看secret信息
[root@swarm-manager mynginx]# docker secret inspect my_secret1 


```

### 9.2 使用secret

```
# 跑一个busybox服务
[root@swarm-manager mynginx]# docker service create --name test1 --secret source=my_secret1,target=test_secret 192.168.10.11:5000/busybox sleep 1000000000
[root@swarm-worker1 ~]# docker exec -it test1.1.jq0ypao7g4fq1gwl61v1oidtf sh
# secrets默认存放目录 /run/secrets/

# 使用secret，启动数据库服务
# source=指定创建的secret,target=指定生成在容器中的文件名
# -e MYSQL_ROOT_PASSWORD_FILE="/run/secrets/mysql_root_password"
[root@swarm-manager mynginx]# docker service create --name mydb1 --secret source=my_secret1,target=mysql_root_password -e MYSQL_ROOT_PASSWORD_FILE="/run/secrets/mysql_root_password" 192.168.10.11:5000/mysql

# 进入容器测试
[root@swarm-worker1 ~]# docker exec -it mydb1.1.oz9016y5jea4wfo5n7ua7ebr1 bash
root@b381f3b7220a:/# mysql -uroot -ppassword
```

### 9.3 创建wordpress服务

![image-20210304155846900](https://gitee.com/luoxian1011/pictures/raw/master/image-20210304155846900.png)

![image-20210304160331485](https://gitee.com/luoxian1011/pictures/raw/master/image-20210304160331485.png)

```
# 下载wordpress镜像
[root@swarm-manager mynginx]# docker pull wordpress
[root@swarm-manager mynginx]# docker tag wordpress:latest 192.168.10.11:5000/wordpress
[root@swarm-manager mynginx]# docker push !$

# 创建私有网络，互通服务
[root@swarm-manager ~]# docker network create --driver overlay myprivate

# 创建db服务，密码可以进入/run/secrets查看
# -e MYSQL_ROOT_PASSWORD_FILE="/run/secrets/mysql_root_password" 
# -e MYSQL_USER="wordpress" 
# -e MYSQL_PASSWORD_FILE="/run/secrets/wordpress_password" 
# -e MYSQL_DATABASE="wordpress"
[root@swarm-manager ~]# docker service create --name mydb --network myprivate --secret source=mysql_root_password,target=mysql_root_password --secret source=mypwd,target=wordpress_password -e MYSQL_ROOT_PASSWORD_FILE="/run/secrets/mysql_root_password" -e MYSQL_USER="wordpress" -e MYSQL_PASSWORD_FILE="/run/secrets/wordpress_password" -e MYSQL_DATABASE="wordpress" 192.168.10.11:5000/mysql

# 创建wordpress服务
# -e WORDPRESS_DB_HOST="mydb:3306"
# -e WORDPRESS_DB_NAME="wordpress" 
# -e WORDPRESS_DB_USER="wordpress" 
# -e WORDPRESS_DB_PASSWORD_FILE="/run/secrets/wordpress_password" 
[root@swarm-manager ~]# docker service create --name wordpress --network myprivate --publish 80:80 --secret source=mypwd,target=wordpress_password -e WORDPRESS_DB_HOST="mydb:3306" -e WORDPRESS_DB_NAME="wordpress" -e WORDPRESS_DB_USER="wordpress" -e WORDPRESS_DB_PASSWORD_FILE="/run/secrets/wordpress_password" 192.168.10.11:5000/wordpress

# 查看服务列表
[root@swarm-manager ~]# docker service ls
ID             NAME        MODE         REPLICAS   IMAGE                                 PORTS
xbq98ytxtkgj   mydb        replicated   1/1        192.168.10.11:5000/mysql:latest       
k2o9940uke8x   wordpress   replicated   1/1        192.168.10.11:5000/wordpress:latest   *:80->80/tcp
```

## 10. stack

 Docker Stack 是为了解决大规模场景下的多服务部署和管理，提供了期望状态，滚动升级，简单易用，扩缩容，健康检查等特性，并且都封装在一个声明式模型当中。

 Docker Stack 部署应用的生命周期：初始化部署 > 健康检查 > 扩容 > 更新 > 回滚。

使用单一声明式文件即可完成部署，即只需要docker-stack.yml文件，使用docker stack deploy命令即可完成部署。

stack 文件其实就是 Docker compose 文件，唯一的要求就是 version 需要为 3.0 或者更高的值。
Stack 完全集成到了 Docker 中，不像 compose 还需要单独安装。

   Docker 适用于开发和测试，而 Docker Stack 则适用于大规模场景和生产环境

### 10.1 创建stack

```
[root@swarm-manager ~]# mkdir mystack
[root@swarm-manager ~]# cd mystack/
[root@swarm-manager mystack]# openssl rand -base64 10 > db_password.txt
[root@swarm-manager mystack]# openssl rand -base64 10 > db_root_password.txt
[root@swarm-manager mystack]# vim docker-compose.yml
```

```
version: '3.1'

services:
  db:
    image: 192.168.10.11:5000/mysql
    volumes:
      - db_data:/var/lib/mysql
    environment:
      MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password
      MYSQL_DATABASE: wordpress
      MYSQL_USER: wordpress
      MYSQL_PASSWORD_FILE: /run/secrets/db_password
    secrets:
      - db_password
      - db_root_password
  wordpress:
    depends_on:
     - db
    image: 192.168.10.11:5000/wordpress
    ports:
      - 9999:80
    environment:
      WORDPRESS_DB_HOST: db:3306
      WORDPRESS_DB_USER: wordpress
      WORDPRESS_DB_PASSWORD_FILE: /run/secrets/db_password
    secrets:
      - db_password
secrets:
  db_password:
    file: db_password.txt
  db_root_password:
    file: db_root_password.txt
volumes:
  db_data:
```

```
[root@swarm-manager mystack]# docker stack deploy -c docker-compose.yml wpstack
Creating network wpstack_default
Creating secret wpstack_db_password
Creating secret wpstack_db_root_password
Creating service wpstack_wordpress
Creating service wpstack_db
```

```
# 查看资源状态
ocker stack services wpstack （查看运行服务数量）
docker stack ps wpstack （查看运行情况）
docker secret ls
```

```
# 更新stack某些属性
# 直接修改yml文件，然后重新部署。
服务名:
    ...
    deploy:
      mode: replicated   # stack 启动时，指定模式
      replicas: 2        # stack 启动时，指定启动多少节点

docker stack  deploy -c docker-compose.yml  wpstack
```

```
# 删除stacke

docker stack rm wpstack
```

